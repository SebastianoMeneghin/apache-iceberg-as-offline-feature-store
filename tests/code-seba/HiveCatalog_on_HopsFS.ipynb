{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the PyIceberg library, then fix the dependency problem with SQLAlchemy library\n",
    "!pip install pyiceberg[pyarrow,duckdb,sql-sqlite] --upgrade\n",
    "!pip install sqlalchemy --upgrade\n",
    "#!pip install sqlalchemy==2.0.28 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b50462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed libraries\n",
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.catalog.hive import HiveCatalog\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "import os\n",
    "import importlib\n",
    "from urllib.parse import urlparse\n",
    "from typing import Dict, List\n",
    "from pyarrow.fs import HadoopFileSystem\n",
    "from functools import lru_cache\n",
    "import time\n",
    "import math\n",
    "from pyiceberg.exceptions import CommitFailedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d25aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ªðŸ§ª ONLY ONCE! ðŸ§ªðŸ§ª\n",
    "# Get the NYC Taxi dataset from the network\n",
    "!curl https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet -o \"/home/yarnapp/hopsfs/Resources/nyc_taxiparquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7c8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜/home/yarnapp/hopsfs/Resources/test_dir/â€™: File exists\n",
      "mkdir: cannot create directory â€˜/tmp/test_data/â€™: File exists\n"
     ]
    }
   ],
   "source": [
    "# Create a folder where to save on HopsFS\n",
    "!mkdir /home/yarnapp/hopsfs/Resources/test_dir/\n",
    "!mkdir /tmp/test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51a79958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default (<class 'pyiceberg.catalog.hive.HiveCatalog'>)\n"
     ]
    }
   ],
   "source": [
    "#catalog_file_path = \"/home/hdfs/iceberg/catalog/pyiceberg_catalog.db\"\n",
    "#hdfs_path_uri = \"hdfs://namenode.service.consul:8020/tmp/test_data\"\n",
    "\n",
    "# Create a catalog\n",
    "test_catalog = HiveCatalog(\n",
    "    \"default\",\n",
    "    **{\n",
    "        \"uri\":\"thrift://metastore.hive.service.consul:9083\",\n",
    "        \"hive.hive2-compatible\":True,\n",
    "        #\"hive.hostname\": \"hive\",\n",
    "        #\"hive.port\":\"9083\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# Print the object catalog, to show the catalog type\n",
    "print(test_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8986be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uri': 'thrift://metastore.hive.service.consul:9083',\n",
       " 'hive.hive2-compatible': True,\n",
       " 'hive.hostname': 'hive',\n",
       " 'hive.port': '9083'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_catalog.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b561462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data previously downloaded into a Parquet DataFrame (df)\n",
    "nyc_data_path = \"/home/yarnapp/hopsfs/Resources/nyc_taxiparquet\"\n",
    "df = pq.read_table(nyc_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acff5f4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TTransportException",
     "evalue": "TSocket read 0 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTTransportException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6999be24ee66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a new namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_catalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_ns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/pyiceberg/catalog/hive.py\u001b[0m in \u001b[0;36mcreate_namespace\u001b[0;34m(self, namespace, properties)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopen_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0mopen_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_annotate_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhive_database\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAlreadyExistsException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNamespaceAlreadyExistsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Database {database_name} already exists\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hive_metastore/ThriftHiveMetastore.py\u001b[0m in \u001b[0;36mcreate_database\u001b[0;34m(self, database)\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \"\"\"\n\u001b[1;32m   2584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_create_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_create_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_create_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/hive_metastore/ThriftHiveMetastore.py\u001b[0m in \u001b[0;36mrecv_create_database\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_create_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0miprot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iprot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2597\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrseqid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miprot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadMessageBegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTMessageType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTApplicationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/thrift/protocol/TBinaryProtocol.py\u001b[0m in \u001b[0;36mreadMessageBegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 raise TProtocolException(type=TProtocolException.BAD_VERSION,\n\u001b[1;32m    147\u001b[0m                                          message='No protocol version header')\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadByte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mseqid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadI32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/thrift/transport/TTransport.py\u001b[0m in \u001b[0;36mreadAll\u001b[0;34m(self, sz)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mhave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhave\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mchunkLen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mhave\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mchunkLen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/thrift/transport/TSocket.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, sz)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTTransportException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unexpected exception\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             raise TTransportException(type=TTransportException.END_OF_FILE,\n\u001b[0m\u001b[1;32m    170\u001b[0m                                       message='TSocket read 0 bytes')\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTTransportException\u001b[0m: TSocket read 0 bytes"
     ]
    }
   ],
   "source": [
    "# Create a new namespace\n",
    "test_catalog.create_namespace(\"test_ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e48528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-04 14:59:50,659 INFO: Defaulting to PyArrow FileIO\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-356203d6d085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a new table \"test_table\", specifying the schema according to the df's schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m test_table = test_catalog.create_table(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"test_ns.nyc_taxi\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# ðŸ§ªðŸ§ª TESTING ðŸ§ªðŸ§ª\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/pyiceberg/catalog/hive.py\u001b[0m in \u001b[0;36mcreate_table\u001b[0;34m(self, identifier, schema, location, partition_spec, sort_order, properties)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mlastAccessTime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_time_millis\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             sd=_construct_hive_storage_descriptor(\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_property_as_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIVE2_COMPATIBLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIVE2_COMPATIBLE_DEFAULT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             ),\n\u001b[1;32m    320\u001b[0m             \u001b[0mtableType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEXTERNAL_TABLE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/hops/anaconda/envs/theenv/lib/python3.10/site-packages/pyiceberg/catalog/__init__.py\u001b[0m in \u001b[0;36m_property_as_bool\u001b[0;34m(properties, property_name, default)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_property_as_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperty_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# Create a new table \"test_table\", specifying the schema according to the df's schema\n",
    "test_table = test_catalog.create_table(\n",
    "    \"test_ns.nyc_taxi\",\n",
    "    schema=df.schema,\n",
    "    # ðŸ§ªðŸ§ª TESTING ðŸ§ªðŸ§ª\n",
    "    # The location now should be added, since in the creation of the catalog we are both specifying the host and the warehouse!\n",
    "    location=\"/tmp/test_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dad5b0",
   "metadata": {},
   "source": [
    "#### Test the data insertion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18595717",
   "metadata": {},
   "source": [
    "Insert the full NYC taxi dataframe in the empy table created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be3f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the dataframe to the test_table, showing the difference between before and after the operation\n",
    "print(\"Start APPEND\")\n",
    "before_len = len(test_table.scan().to_arrow())\n",
    "\n",
    "test_table.append(df)\n",
    "\n",
    "print('End APPEND')\n",
    "after_len  = len(test_table.scan().to_arrow())\n",
    "print(\"Before the append operation, there were \" + str(before_len) + \"rows in the table\")\n",
    "print(\"After  the append operation, there were \" + str(after_len)  + \"rows in the table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012610fa",
   "metadata": {},
   "source": [
    "#### Test multiple APPEND operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58350b55",
   "metadata": {},
   "source": [
    "In order to test several consecutive APPEND operations, the Arrow Dataframe containing the NYC Taxi data is transformed in Pandas Dataframe, then divided in small part of 1000 rows each.\n",
    "âš ï¸ Depending on \"how_many\" APPEND operations you want to perform, change the former parameters in the following cell.\n",
    "\n",
    "Several errors might arise, but those should not be related to the functioning of the PyIceberg library: the problem should instead reside in the underlying infrastructure (Jupyter, Hopsworks UI, VM, File access permissions ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d881981",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog(\"default\",**{\"uri\":\"sqlite:////home/yarnapp/hopsfs/Resources/test_dir/pyiceberg_catalog.db\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b82738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data previously downloaded into a Parquet DataFrame (df)\n",
    "nyc_data_path = \"/home/yarnapp/hopsfs/Resources/nyc_taxiparquet\"\n",
    "arrow_df      = pq.read_table(nyc_data_path)\n",
    "\n",
    "# Create a set for randomizing the insertion\n",
    "insert_set = set()\n",
    "for i in range(1, math.floor(arrow_df.shape[0]/1000), 2):\n",
    "    insert_set.add(i)\n",
    "    \n",
    "# Transform the arrow dataframe into a pandas DataFrame\n",
    "df_append = pd.DataFrame()\n",
    "df_append = arrow_df.to_pandas()\n",
    "\n",
    "# Set how many times you want to repeat the APPEND operation\n",
    "how_many = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the table where to append the new data\n",
    "table_append = catalog.load_table(\"test_ns.nyc_taxi\")\n",
    "\n",
    "for i in range(how_many):\n",
    "    elem = insert_set.pop()\n",
    "    partial_df = df_append[elem*1000:1000*(elem + 1)]\n",
    "    partial_table = pyarrow.Table.from_pandas(partial_df)\n",
    "\n",
    "    # Append the dataframe to the test_table, showing the difference between before and after the operation\n",
    "    print(\"Start APPEND\")\n",
    "    before_len = len(table_append.scan().to_arrow())\n",
    "    \n",
    "    table_append.append(partial_table)\n",
    "    \n",
    "    print('End APPEND')\n",
    "    after_len  = len(table_append.scan().to_arrow())\n",
    "    print(\"Before the append operation, there were \" + str(before_len) + \"rows in the table\")\n",
    "    print(\"After  the append operation, there were \" + str(after_len)  + \"rows in the table\")\n",
    "    \n",
    "    if i == how_many - 1:\n",
    "        print('\\n\\n ** All the APPEND operations have been completed **')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdbd457",
   "metadata": {},
   "source": [
    "#### Test the schema evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe, equal to df but with a new column\n",
    "updated_df = df.append_column(\"tip_per_mile\", pc.divide(df[\"tip_amount\"], df[\"trip_distance\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2132ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog(\"default\",**{\"uri\":\"sqlite:////home/yarnapp/hopsfs/Resources/test_dir/pyiceberg_catalog.db\"})\n",
    "table   = catalog.load_table(\"test_ns.nyc_taxi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract then the new schema information and save them in a new file\n",
    "with table.update_schema() as update_schema:\n",
    "    update_schema.union_by_name(updated_df.schema)\n",
    "    \n",
    "# Overwrite the previous table, replacing the old dataframe with a new one\n",
    "table.overwrite(updated_df)\n",
    "print(table.scan().to_arrow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ªðŸ§ª TESTING ðŸ§ªðŸ§ª\n",
    "\n",
    "# Get the table into a pandas DataFrame, in order to verift its length and integrity.\n",
    "prova = table.scan().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6ce62",
   "metadata": {},
   "source": [
    "#### Test the table scan and file retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = table.scan(row_filter=\"tip_per_mile > 0\").to_arrow()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0906635e",
   "metadata": {},
   "source": [
    "---\n",
    "#### @FINAL Delete all the data and files created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just call it if you are at the end of your own test\n",
    "! rm -r /home/yarnapp/hopsfs/Resources/test_dir\n",
    "! rm -r /tmp/test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2773bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ªðŸ§ª TESTING ðŸ§ªðŸ§ª\n",
    "\n",
    "# Sometimes a file \"default\" is created here. This could cause problem, so run this cell to remove it.\n",
    "! rm -r /home/yarnapp/hopsfs/Experiments/default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af2cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ªðŸ§ª TESTING ðŸ§ªðŸ§ª\n",
    "\n",
    "!echo '.databases'|sqlite3 default\n",
    "#!echo '.databases'|sqlite3 default"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
