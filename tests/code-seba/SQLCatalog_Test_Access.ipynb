{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a86a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a258c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed libraries\n",
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.catalog.sql import SqlCatalog\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "import math\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "import os\n",
    "import importlib\n",
    "from urllib.parse import urlparse\n",
    "from typing import Dict, List\n",
    "from pyarrow.fs import HadoopFileSystem\n",
    "from functools import lru_cache\n",
    "import time\n",
    "from pyiceberg.exceptions import CommitFailedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog(\"default\",**{\"uri\":\"sqlite:////home/yarnapp/hopsfs/Resources/test_dir/pyiceberg_catalog.db\"})\n",
    "table = catalog.load_table(\"test_ns.nyc_taxi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf48e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data previously downloaded into a Parquet DataFrame (df)\n",
    "nyc_data_path = \"/home/yarnapp/hopsfs/Resources/nyc_taxiparquet\"\n",
    "df = pq.read_table(nyc_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ca43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data previously downloaded into a Parquet DataFrame (df)\n",
    "nyc_data_path = \"/home/yarnapp/hopsfs/Resources/nyc_taxiparquet\"\n",
    "arrow_df      = pq.read_table(nyc_data_path)\n",
    "\n",
    "# Create a set for randomizing the insertion\n",
    "insert_set = set()\n",
    "for i in range(1, math.floor(arrow_df.shape[0]/1000), 2):\n",
    "    insert_set.add(i)\n",
    "    \n",
    "# Transform the arrow dataframe into a pandas DataFrame\n",
    "df_append = pd.DataFrame()\n",
    "df_append = df_append.to_pandas()\n",
    "\n",
    "# Set how many times you want to repeat the APPEND operation\n",
    "how_many = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = catalog.load_table(\"test_ns.nyc_taxi\")\n",
    "#test_table = test_catalog.load_table(\"test_ns.nyc_taxi\")\n",
    "\n",
    "for i in range(how_many):\n",
    "    elem = insert_set.pop()\n",
    "    partial_df = pd_df[elem*1000:1000*(elem + 1)]\n",
    "    partial_table = pyarrow.Table.from_pandas(partial_df)\n",
    "\n",
    "    # Append the dataframe to the test_table, showing the difference between before and after the operation\n",
    "    print(\"Before the append operation, there are \" + str(len(table.scan().to_arrow())) + \"rows in the table\")\n",
    "    table.append(partial_table)\n",
    "    print(\"After the append operation, there are \" + str(len(table.scan().to_arrow())) + \"rows in the table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69023b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
