This thesis project aims to diminish read and write latency (seconds) and thus enhance data throughput (rows/second) for operations on the Hopsworks offline feature store. This research will evaluate the performance of the existing legacy pipeline, which utilises Spark for writing, against PyIceberg pipeline on a small-scale dataset by assessing variations in latency and throughput during read and write operations. If the PyIceberg alternative is shown to be a more efficient option, Hopsworks AB will contemplate including this pipeline into their application. The same assessment will be conducted, within the same data scale domain, between PyIceberg and delta-rs pipelines.

The overall ramifications of this thesis are far larger, given Spark's prominence within the open-source community, which has had almost 3000 contributors during its existence \cite{ApacheSparkOpen}. Opting using PyIceberg or delta-rs instead of Spark provides developers with a wider array of options for managing small-scale data (1 GB - 100 GB). This thesis work also provides an industrial use case, that can be used to understand which alternative to Spark could fit the best a specific developer need.