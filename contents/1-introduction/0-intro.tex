Data lakehouses' adoption reached in 2024 a critical mass, with more than 50\% organizations running their analytics on these platform, and projection up to 67\% within 2027 \cite{StateDataLakehouse2025}. A data lakehouse is a modern data architecture that creates a single platform by combining the key benefits of data lakes (large repositories of raw data in its original form) and data warehouses (organized sets of structured data). Thus, data lakehouse is a cost-effective architecture \cite{DatalakehouseCostEfficiency} that bridges those architectures by providing the scalability of the data lakes together with analytical computations and \gls{ACID} properties of data warehouses \cite{lakehouse2021}. This surge is strongly related to the acceleration of AI adoption \cite{SurgeAI2024}, which put pressure on storage solutions and data processing capabilities \cite{StateDataLakehouse2025}. In support to this, data lakehouse systems include data partitioning, reducing the query computational needs, support schemas evolution and provide "time travel" capabilities, enabling data versioning over time \cite{crociDataLakehouseHype2022}.

From the first appearance of data lakehouses \cite{WhatLakehouse2020}, three primary applications arose \cite{ApacheHudiVs}: 
\begin{enumerate} 
    \item \textbf{Apache Hudi}: introduced by Uber in 2017, then supported by Alibaba, Bytedance, Uber and Tencent \cite{rajaperumalUberEngineeringIncremental2017}.
    \item \textbf{Apache Iceberg}: open sourced by Netflix~\footnote{Netflix first implementation at \url{https://github.com/Netflix/iceberg}} in 2018, now used by Airbnb, Apple, Expedia, LenkedIn, Lyft \cite{IcebergExamples2024}.
    \item \textbf{Delta Lake}: open sourced by Databricks in 2019 \cite{armbrustDeltaLakeHighperformance2020}, supported now by Databricks and Microsoft.
\end{enumerate}

Apache Iceberg (from now on, Iceberg) was originally developed as an alternative to Apache Hive (from now on, Hive), a data warehouse system that enables querying of large datasets stored in Hadoop using a \gls{SQL}-like language. Iceberg is designed to manage bigger datasets with frequent updates and deletions, and to support schema evolution, going thus beyond Hive's capabilities \cite{shiranApacheIcebergDefinitive2024}. This is possible thanks to the Iceberg metadata management layer, which enables data warehouse-like capabilities via cloud object storage. In 2024, Iceberg has consolidated its position in 2024 \cite{IcebergNewHadoop}, and has been recently included in arguably all the major big data vendors' solutions \cite{BigDataVendorIceberg}.

Apache Hudi (from now on, Hudi), Iceberg and Delta Lake were initially designed to fit a single engine, respectively Hive, Trino and Apache Spark (from now on, Spark) \cite{ApacheHudiVs}. These three solutions have been improved to better scalability and flexibility needs, each integrating new engners and features \cite{OngoingEvolutionTableFormat}. Despite being beneficial, this evolution highlights a potential limitation: systems developed in differnt ways performe differently, and depending on the use case, even widespread solutions might not always be the optimal solution. For example, integrating the system with Spark, a query and compute engine \cite{zahariaApacheSparkUnified2016}, is a good solution when processing massive datasets (1 TB+) on the cloud. However, it is yet unclear how good this solution could perform when processing smaller datasets (1 GB to 100 GB) \cite{Khazanchi1801362}. 

Such Spark limitations of Spark are also brought to light by technologies such as the Python library Polars~\cite{vinkWroteOneFastest2021} and the \gls{DBMS} DuckDB~\cite{raasveldtDuckDBEmbeddableAnalytical2019}, that combined to process data locally, in small quantities, showed much better performance than a Spark Cluster. This solution further avoids the high expenses and computation time lying behind Spark usage in the same scenario. Thus, similar solutions employed in small-scale scanarios (from 1GB to 100GB) could greatly increase performance and reduce costs~\cite{ebergenUpdatesH2OAi2023}~\cite{BenchmarkResultsSpark}.

Remaining in the data science domain, Python has perhaps become the de facto standard programming language. Python is arguably the most popular general-purpose programming language \cite{TIOBEIndex, StackOverflowDeveloper, PythonTopLanguage}, and the go-to option for \gls{ML} and \gls{AI} applications \cite{python-machine-learning}. Among the most commonly used libraries by \gls{ML} application developers, we find NumPy and Pandas \cite{StackOverflowDeveloper}, while PyTorch and TensorFlow are the first two for \gls{NN} libraries. Accessing data lakehouse solutions via a Python client would be the favorite option for most of \gls{ML} and \gls{AI} developers, so they do not have to resort to alternatives, such as Spark and its \glspl{API} (e.g., PySpark). 

Therefore, supporting Iceberg with a native Python client would be directly beneficial for Hopsworks AB, the host company of this master thesis. Hopsworks AB develops a homonymous \gls{AI} Lakehouse for \gls{ML}. This software includes a multi-user data platform, called feature store, that enables storage and access of reusable features~\footnote{Definition from the company's website at \url{https://www.hopsworks.ai/}}. It also implements resource-efficient and point-in-time joins between datasets, adding historical retrieval features to saved data \cite{Pettersson1695672}.

This project seeks to reduce latency (in seconds), thus increasing throughput (in rows/second), of reading and writing data on Iceberg tables, as offline feature store in Hopsworks. At time of writing, the writing pipeline is Spark-based and uses Hudi as \gls{OTF}, while this thesis seeks to employ Iceberg without Spark-dependencies. If the hypothesis that a faster non-Spark alternative is possible is proved, Hopsworks AB will consider this alternative as an integration or replacement of their current open-source feature store implementation. This could considerably improve the experience of Python users working with small-scale datasets (1 GB to 100 GB). More broadly, this thesis will discuss the feasibility of Spark alternatives in small-scale use scenarios \cite{manfrediReducingReadWrite2024}.

The primary contributions of this work are:
\begin{itemize}
    \item The evaluation of the possible technologies for the integrations between Iceberg and Hopsworks feature store, and the selection of the best one according to defined requirements, described in Section \ref{subsec:integration_reqs}. The solution most fitting the requirements consists of SQLCatalog as catalog, DuckDB as query engine, and PyArrowFileIO as FileIO.
    \item The results of the experiments conducted on the newly integrated PyIceberg system and the Hudi legacy system, showing differences in latency and throughput for read and write operations. These experiments were conducted fifty times, with different dataset sizes and \gls{CPU} settings. The new system, accessing Iceberg from a Python client, reduced write latency by 40 to 140 times, and read latency by 15 to 60 times in the smaller tables, compared to what was experienced using the old system.
    \item The results of the comparison between the newly integrated PyIceberg system and the recently implemented delta system \cite{manfrediReducingReadWrite2024}, on which the same experiments above were conducted in a parallel thesis work. The PyIceberg system has write latency from 5 to 7 times lower compared to what was experienced using the delta-rs system, and comparable read latency. The delta-rs system showed better support for multiple \gls{CPU} cores setting.
\end{itemize}

These findings provide a significant contribution to the data management industry, supporting existing studies on the constraints of utilising Spark with small-scale volumes of data. Furthermore, the reproducibility of the experiments conducted adds great value to this work. Thanks to the well-defined environment and the available code, these experiments can be used as starting or final point for further exploration and testing in this field. 