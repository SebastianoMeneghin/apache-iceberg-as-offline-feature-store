Data lakehouses' adoption reached in 2024 a critical mass, with more than 50\% of organizations running their analytics on these platform, and projection up to 67\% within 2027 \cite{StateDataLakehouse2025}. The data lakehouse architecture \cite{lakehouse2021} is cost efficient compared to traditional data warehouse and data lakes \cite{DatalakehouseCostEfficiency}, and bridges those architectures by providing the scalability of data lakes together with analytical computations and \gls{ACID} properties of data warehouses \cite{lakehouse2021}. This surge is also strongly related to the AI adoption acceleration \cite{SurgeAI2024}, which put pressure on storage solutions and data processing capabilities \cite{StateDataLakehouse2025}. In support to this, data lakehouse systems include data partitioning, reducing the query computational needs, support schemas evolution and provide "time travel" capabilities, enabling data versioning over time \cite{crociDataLakehouseHype2022}.

From the first appearance of data lakehouses \cite{WhatLakehouse2020}, three primary applications arose \cite{ApacheHudiVs}: 
\begin{enumerate} 
    \item \textbf{Apache Hudi}: introduced by Uber in 2017, then supported by Alibaba, Bytedance, Uber and Tencent \cite{rajaperumalUberEngineeringIncremental2017}.
    \item \textbf{Apache Iceberg}: open sourced by Netflix~footnote{Netflix first implementation at \url{https://github.com/Netflix/iceberg}} in 2018, now used by Airbnb, Apple, Expedia, LenkedIn, Lyft \cite{IcebergExamples2024}.
    \item \textbf{Delta Lake}: open sourced by Databricks in 2019 \cite{armbrustDeltaLakeHighperformance2020}, supported now by Databricks and Microsoft.
\end{enumerate}

Apache Iceberg (from now on, Iceberg) was originally developed as an alternative to Apache Hive (from now on, Hive), a data warehousing system that enabling querying of large datasets stored in Hadoop using a \gls{SQL}-like language. Iceberg is designed to manage bigger datasets with frequent updates and deletions, and to support schema evolution, which both go beyond Hive's capabilities \cite{shiranApacheIcebergDefinitive2024}. This is possible thanks to the Iceberg metadata management layer, that enables data warehouse-like capabilities via cloud object storage. Iceberg has consolidated its position in 2024 \cite{IcebergNewHadoop}, being recently included in all the major big data vendors' solutions \cite{BigDataVendorIceberg}.

Apache Hudi (from now on, Hudi), Iceberg and Delta Lake were initially designed to support a specific engine, respectively Hive, Trino and Apache Spark (from now on, Spark) \cite{ApacheHudiVs}. These three solutions have been improved to better address industry needs and flexibility issues, and now provides integrations for several engines \cite{OngoingEvolutionTableFormat}. This evolution, while beneficial, highlights a potential limitation: even solutions which have gained widespread adoption might not be the optimal solution in all the cases. For example, integrating the system with Spark, a data query and processing engine \cite{zahariaApacheSparkUnified2016}, works well for processing massive datasets (1 TB+) on the cloud, however it is yet unclear if it works well for processing smaller datasets (1 GB to 100 GB) \cite{Khazanchi1801362}. 

Limitations of Spark are also brought to light by technologies such as the python library Polars~\cite{vinkWroteOneFastest2021} and the \gls{DBMS} DuckDB~\cite{raasveldtDuckDBEmbeddableAnalytical2019}. A Spark cluster performs worse than other options when processing data locally with lesser quantities. Thus, employing Spark eventually results in higher expenses and computation time~\cite{ebergenUpdatesH2OAi2023}~\cite{BenchmarkResultsSpark}. With small-scale (from 1 GB to 100 GB) scenarios, different solutions would greatly increase performance.

Remaining in the data science domain, in the latest year Python got the title of widely used programming language \cite{nagpalPythonDataAnalytics2019}. Indeed, Python is currently the most popular general-purpose programming language \cite{TIOBEIndex, StackOverflowDeveloper}, and the go-to option for \gls{ML} and \gls{AI} applications \cite{python-machine-learning}. Among the most used libraries by \gls{ML} application developers, we find NumPy and Pandas \cite{StackOverflowDeveloper}, while PyTorch and TensorFlow are the first two for \gls{NN} libraries. Furthermore, in late 2024, due to its simplicity and high level of abstraction, Python overtook JavaScript as the most popular language on GitHub \cite{PythonTopLanguage}. Accessing data lakehouse solutions via Python client would be the favourite option for most of \gls{ML} and \gls{AI} developers, so they would not have to resort to alternatives, as Spark and its Python \gls{API} (PySpark). 

Thus, supporting Iceberg with a native Python client would be directly beneficial for Hopsworks \gls{AB}, the host company of this master thesis. Hopsworks \gls{AB} develops a homonymous \gls{AI} Lakehouse for \gls{ML}. This software includes a multi-user data platform, called feature store, that enables storage and access of reusable features~\footnote{Definition from the company's website at \url{https://www.hopsworks.ai/}}. This also implements resource-efficient and point-in-time join between datasets, adding historical retrieval features to saved data \cite{Pettersson1695672}.

This project seeks to reduce latency (seconds), thus increasing throughput (rows/second), of reading and writing data on Iceberg tables, as offline feature store in Hopsworks. Currently, the writing pipeline is Spark-based, supported by Hudi's table format: the project's main hypothesis is that a quicker non-Spark alternative is possible. If proved to be successful, Hopsworks \gls{AB} will consider this alternative as an integration or replacement of their current open-source feature store implementation. This could considerably improve the experience of Python users, while working with small-scale datasets (1 GB to 100 GB). More broadly, this thesis will discuss the feasibility of Spark alternatives in small-scale use scenarios \cite{manfrediReducingReadWrite2024}.

\generalExpl{Revise the following part of the introduction once drafted implementation and conclusion chapters}

This work's primary contributions are:
\begin{itemize}
    \item \textbf{TO BE DISCUSSED:} The evaluation of the possible integration between Iceberg and Hopsworks feature store, and the selection of the best one according to \todo{insert defined requirements}. \todo{insert the selected one and explain the main reasons}
    \item The results of the experiments conducted on the newly integrated and the older Hopsworks feature store, showing differences by latency and throughput, on read and write operations. These experiments were conducted fifty times, with different dataset sizes and \gls{CPU} settings. The new system,accessing Iceberg from a Python client, reduced write latency by \todo{add write percentual improvement} and read latency by \todo{add read percentual improvement}, compared to what experimented using the old system.
    \item The comparison of the above results with the results of a parallel conducted thesis \cite{manfrediReducingReadWrite2024}, investigating native Python access for Delta Lake as Spark alternative.
\end{itemize}

These findings provide a significant addition to the data management industry, supporting existing studies on the constraints of utilising Spark with small-scale volumes of data. Furthermore, the reproducibility of the experiments conducted adds great value to this work. Thanks to the well-defined environment and the available code, these experiments be used as starting or final point for further exploration and testing in this field.